{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add your path here\n",
    "current_path = os.getcwd()\n",
    "main_path = os.path.join(current_path,'dataset')\n",
    "if not os.path.exists(main_path):\n",
    "    os.mkdir(main_path)\n",
    "\n",
    "out_folder = os.path.join(main_path,'combined')\n",
    "if not os.path.exists(out_folder):\n",
    "    os.mkdir(out_folder)\n",
    "\n",
    "path = os.path.join(main_path,'weather data telangana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_substrings(column_name):\n",
    "    ## Remove all strings with brackets\n",
    "    new_name = re.sub(r'\\s*\\([^)]*\\)|\\s+$', '', column_name)\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_column_names(column_name):\n",
    "    if column_name in ['cumm_rainfall', 'rainfall', 'rain']:\n",
    "        return 'rain'\n",
    "    elif column_name in ['odate','date']:\n",
    "        return 'date'\n",
    "    elif column_name in ['min temp', 'min_temp', 'temp_min']:\n",
    "        return 'temp_min'\n",
    "    elif column_name in ['max temp', 'max_temp', 'temp_max']:\n",
    "        return 'temp_max'\n",
    "    elif column_name in ['min humidity', 'min_humidity', 'humidity_min']:\n",
    "        return 'humidity_min'\n",
    "    elif column_name in ['max humidity', 'max_humidity', 'humidity_max']:\n",
    "        return 'humidity_max'\n",
    "    elif column_name in ['min wind speed', 'min_wind_speed', 'wind_speed_min']:\n",
    "        return 'wind_speed_min'\n",
    "    elif column_name in ['max wind speed', 'max_wind_speed', 'wind_speed_max']:\n",
    "        return 'wind_speed_max'\n",
    "    else:\n",
    "        return column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(df):\n",
    "    df = df.loc[:, ~df.columns.str.contains('^(?:Unnamed|mcode|dcode|dmcode|row_id)', case=False)]\n",
    "    df = df.rename(columns=remove_substrings)\n",
    "    df = df.rename(columns= correct_column_names)\n",
    "    df.columns = [elem.lower() for elem in list(df)]\n",
    "    df = df.assign(date=pd.to_datetime(df['date']))\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n"
     ]
    }
   ],
   "source": [
    "years = os.listdir(path)\n",
    "for i in years:\n",
    "    months = os.listdir(os.path.join(path,i))\n",
    "    df_array = []\n",
    "    print(i)\n",
    "    for j in months:\n",
    "        exact_path = os.path.join(path,i,j)\n",
    "        try:\n",
    "            df_array.append(pd.read_csv(exact_path))\n",
    "        except:\n",
    "            try:\n",
    "                df_array.append(pd.read_excel(exact_path))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "    final_dataframe = pd.DataFrame()\n",
    "    \n",
    "    ## Cleaning the dataframes\n",
    "    for data in df_array:      \n",
    "        data = cleaner(data)\n",
    "        final_dataframe = pd.concat([final_dataframe,data],ignore_index=True)        \n",
    "\n",
    "    final_dataframe.groupby('district')\n",
    "    final_dataframe.reset_index(drop = True)\n",
    "    final_dataframe = final_dataframe.fillna(0)\n",
    "    year_string = 'TS Weather data ' + i + '.csv'\n",
    "    df_name = os.path.join(out_folder,year_string)\n",
    "    final_dataframe = final_dataframe.rename(columns= correct_column_names)\n",
    "    final_dataframe.to_csv(df_name,index=False)\n",
    "    # print(final_dataframe.head())\n",
    "    # else:\n",
    "    #     file = os.listdir(os.path.join(path,i))\n",
    "    #     for j in file:\n",
    "    #         print(i)\n",
    "    #         exact_path = os.path.join(path,i,j)\n",
    "    #         df = pd.read_csv(exact_path)\n",
    "    #         df.rename(columns = {'odate':'date'},inplace= True)\n",
    "    #         df['date'] = pd.to_datetime(df['date'])\n",
    "    #         file_path = os.path.join(out_folder,' TS Weather data 2018.csv')\n",
    "    #         df.to_csv(file_path,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# district_path = r\"D:\\NASSCOM\\dataset\\district-group\"\n",
    "district_folder = os.path.join(main_path,'district-group')\n",
    "if not os.path.exists(district_folder):\n",
    "    os.mkdir(district_folder)\n",
    "\n",
    "files = os.listdir(out_folder)\n",
    "for file in files:\n",
    "    file_path = os.path.join(out_folder, file)\n",
    "    district_file = os.path.join(district_folder,file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.groupby(['district','date']).mean()\n",
    "    df.to_csv(district_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(district_folder)\n",
    "df = pd.DataFrame()\n",
    "for f in files:\n",
    "    file = os.path.join(district_folder,f)\n",
    "    data = pd.read_csv(file)\n",
    "    df = pd.concat([df,data],ignore_index=True)\n",
    "    \n",
    "full_merged_dataset_dir = os.path.join(main_path,'super_merged_data')\n",
    "full_merged_output_path = os.path.join(full_merged_dataset_dir,'complete_merged.csv')\n",
    "\n",
    "if not os.path.exists(full_merged_dataset_dir):\n",
    "    os.mkdir(full_merged_dataset_dir)\n",
    "\n",
    "df.to_csv(full_merged_output_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('tensorflowenv_20220122')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2e8fcb74b459646169e5c12b1b3bad8bafdc0d857aabfcf8ac08160d16192a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
